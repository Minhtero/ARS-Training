{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "b1ef3f30",
      "cell_type": "markdown",
      "source": "\n# üìö Ng√†y 2 ‚Äî PyTorch & Deep Learning cho Computer Vision (Chu·∫©n b·ªã ph·ªèng v·∫•n)\n**Th·ªùi l∆∞·ª£ng ƒë·ªÅ xu·∫•t:** 5 gi·ªù h·ªçc + 1 gi·ªù th·ª±c h√†nh (code).\n\n**M·ª•c ti√™u:**\n\n- Hi·ªÉu PyTorch c∆° b·∫£n: `torch.tensor`, `requires_grad`, `nn.Module`, `forward`, optimizer, `loss.backward()`.\n\n- L√†m vi·ªác v·ªõi `DataLoader` (MNIST), x√¢y CNN nh·ªè (2 conv + 2 fc), vi·∫øt training loop, t√≠nh accuracy, l∆∞u/load model.\n- In confusion matrix (d√πng `sklearn`) v√† so s√°nh ·∫£nh h∆∞·ªüng c·ªßa batch size (64 vs 128).\n\n\n**Ghi ch√∫:** Notebook n√†y ƒë∆∞·ª£c vi·∫øt b·∫±ng ti·∫øng Vi·ªát, k√®m nhi·ªÅu ch√∫ th√≠ch. N·∫øu ch·∫°y tr√™n Colab, nh·ªõ ch·ªçn Runtime > GPU.\n",
      "metadata": {}
    },
    {
      "id": "6c9e9fd5",
      "cell_type": "markdown",
      "source": "\n## 0) C√†i ƒë·∫∑t (n·∫øu c·∫ßn)\n\nC√°c d√≤ng d∆∞·ªõi ƒë√¢y c√≥ th·ªÉ c·∫ßn ch·∫°y **n·∫øu m√°y/em ch∆∞a c√†i** PyTorch, torchvision, scikit-learn, matplotlib. ·ªû Colab th∆∞·ªùng ƒë√£ c√†i s·∫µn (ho·∫∑c d√πng `pip` ph√π h·ª£p v·ªõi CUDA).\n\n```bash\n# Ch·ªâ ch·∫°y n·∫øu c·∫ßn. C√≥ th·ªÉ c·∫ßn thay command install ph√π h·ª£p v·ªõi CUDA tr√™n m√°y em.\n# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n# !pip install scikit-learn matplotlib tqdm\n```\n\nN·∫øu em d√πng Colab: Runtime > Change runtime type > GPU, sau ƒë√≥ ch·∫°y l·∫°i cell import.\n",
      "metadata": {}
    },
    {
      "id": "7ca786c0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# 1) Imports & Device\nimport os\nimport time\nimport random\nfrom collections import OrderedDict\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms\n\n# Optional: tqdm for progress bars\ntry:\n    from tqdm import tqdm\nexcept Exception:\n    tqdm = lambda x: x\n\n# sklearn for confusion matrix and classification report\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Device (GPU n·∫øu c√≥)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device:', device)\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\n# Create output folder\nos.makedirs('/mnt/data/pytorch_day2', exist_ok=True)\nprint('/mnt/data/pytorch_day2 is ready')\n",
      "outputs": []
    },
    {
      "id": "1c47482a",
      "cell_type": "markdown",
      "source": "\n## 2) Datasets & DataLoader (MNIST)\n- Ta s·ª≠ d·ª•ng MNIST ƒë·ªÉ t·∫≠p trung v√†o pipeline: download, transform, DataLoader.\n- N·∫øu mu·ªën test CIFAR10, ch·ªâ c·∫ßn ƒë·ªïi dataset v√† transforms t∆∞∆°ng ·ª©ng.\n",
      "metadata": {}
    },
    {
      "id": "e60cd47b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# 2.1 Transforms: normalize theo mean/std c·ªßa MNIST (grayscale)\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),            # tr·∫£ v·ªÅ tensor shape (C,H,W) v√† normalize [0,1]\n    transforms.Normalize((0.1307,), (0.3081,))  # mean/std MNIST\n])\n\n# 2.2 Download dataset\nroot = '/mnt/data/pytorch_day2/data'\ntrain_dataset = datasets.MNIST(root=root, train=True, download=True, transform=transform)\ntest_dataset  = datasets.MNIST(root=root, train=False, download=True, transform=transform)\n\nprint('Train size =', len(train_dataset))\nprint('Test size  =', len(test_dataset))\n\n# 2.3 Create DataLoader: default batch_size 64 (we will experiment with 128 later)\nBATCH_SIZE = 64\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\ntest_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n# Visual check: show some samples\nimport matplotlib.pyplot as plt\n\ndef show_images(dataset, n=6):\n    fig, axes = plt.subplots(1, n, figsize=(12,2))\n    for i in range(n):\n        img, label = dataset[i]\n        img = img.squeeze().numpy()\n        axes[i].imshow(img, cmap='gray')\n        axes[i].set_title(str(label))\n        axes[i].axis('off')\n    plt.show()\n\nshow_images(train_dataset, n=6)\n",
      "outputs": []
    },
    {
      "id": "620649d9",
      "cell_type": "markdown",
      "source": "\n## 3) X√¢y CNN nh·ªè (2 conv layers + 2 fully connected)\n- M√¥ t·∫£ ki·∫øn tr√∫c: Conv -> ReLU -> MaxPool -> Conv -> ReLU -> MaxPool -> Flatten -> FC -> ReLU -> FC(logits)\n- Ta gi·∫£i th√≠ch shapes t·ª´ng b∆∞·ªõc trong code.\n",
      "metadata": {}
    },
    {
      "id": "beff7fd1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import torch.nn.functional as F\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(SimpleCNN, self).__init__()\n        # Conv1: input channels=1 (MNIST), output channels=16, kernel=3\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # output size -> (16,28,28)\n        self.bn1 = nn.BatchNorm2d(16)\n        # Conv2: input 16, output 32, kernel=3\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # output size -> (32,14,14) after pool\n        self.bn2 = nn.BatchNorm2d(32)\n        # After two pools: input 28x28 -> 14x14 -> 7x7\n        # FC layers: flatten 32*7*7 -> hidden 128 -> out num_classes\n        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        # x: (batch, 1, 28, 28)\n        x = self.conv1(x)            # -> (batch,16,28,28)\n        x = self.bn1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)      # -> (batch,16,14,14)\n\n        x = self.conv2(x)           # -> (batch,32,14,14)\n        x = self.bn2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)      # -> (batch,32,7,7)\n\n        x = x.view(x.size(0), -1)   # flatten -> (batch, 32*7*7)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)             # logits\n        return x\n\n# Instantiate and print parameter count\nmodel = SimpleCNN().to(device)\nprint(model)\n\n# Count parameters\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint('Trainable params:', count_parameters(model))\n",
      "outputs": []
    },
    {
      "id": "d86a118d",
      "cell_type": "markdown",
      "source": "\n## 4) Loss, Optimizer & Utility functions\n- Ch√∫ng ta s·∫Ω d√πng `CrossEntropyLoss` (k·∫øt h·ª£p softmax + NLL) v√† `optim.SGD` v·ªõi momentum.\n- Vi·∫øt h√†m `train_one_epoch`, `evaluate` v√† `compute_accuracy`.\n",
      "metadata": {}
    },
    {
      "id": "3f4444e5",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# 4.1 Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n# Optional LR scheduler\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n\n# 4.2 Utility: accuracy\ndef compute_accuracy(logits, labels):\n    preds = torch.argmax(logits, dim=1)\n    correct = (preds == labels).sum().item()\n    return correct / labels.size(0)\n\n# 4.3 Train & Eval loops\n\ndef train_one_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    total = 0\n    for images, labels in tqdm(loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward\n        loss.backward()\n        optimizer.step()\n\n        # Stats\n        batch_size = labels.size(0)\n        running_loss += loss.item() * batch_size\n        running_corrects += (torch.argmax(outputs, dim=1) == labels).sum().item()\n        total += batch_size\n\n    epoch_loss = running_loss / total\n    epoch_acc  = running_corrects / total\n    return epoch_loss, epoch_acc\n\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            batch_size = labels.size(0)\n            running_loss += loss.item() * batch_size\n            running_corrects += (torch.argmax(outputs, dim=1) == labels).sum().item()\n            total += batch_size\n\n            all_preds.append(torch.argmax(outputs, dim=1).cpu().numpy())\n            all_labels.append(labels.cpu().numpy())\n\n    epoch_loss = running_loss / total\n    epoch_acc  = running_corrects / total\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n    return epoch_loss, epoch_acc, all_preds, all_labels\n",
      "outputs": []
    },
    {
      "id": "74ea704d",
      "cell_type": "markdown",
      "source": "\n## 5) Full training script (run experiments)\n- H√†m `run_training` s·∫Ω train model trong N epochs, l∆∞u l·ªãch s·ª≠ loss/acc v√† l∆∞u model cu·ªëi.\n- Sau khi train, ta s·∫Ω evaluate v√† in confusion matrix.\n",
      "metadata": {}
    },
    {
      "id": "b3030607",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def plot_history(history, title_prefix=''):\n    epochs = np.arange(1, len(history['train_loss'])+1)\n    plt.figure(figsize=(10,4))\n    plt.subplot(1,2,1)\n    plt.plot(epochs, history['train_loss'], label='train_loss')\n    plt.plot(epochs, history['val_loss'], label='val_loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title(title_prefix + ' Loss')\n\n    plt.subplot(1,2,2)\n    plt.plot(epochs, history['train_acc'], label='train_acc')\n    plt.plot(epochs, history['val_acc'], label='val_acc')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.title(title_prefix + ' Accuracy')\n    plt.show()\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix'):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.figure(figsize=(6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, format(cm[i, j], fmt),\n                     horizontalalignment='center',\n                     color='white' if cm[i, j] > thresh else 'black')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.show()\n\n\ndef run_training(model, train_loader, val_loader, optimizer, criterion, device, epochs=5, scheduler=None, model_name='model.pth'):\n    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n    best_val_acc = 0.0\n    best_state = None\n    for epoch in range(1, epochs+1):\n        start = time.time()\n        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n        val_loss, val_acc, val_preds, val_labels = evaluate(model, val_loader, criterion, device)\n        if scheduler is not None:\n            scheduler.step()\n        elapsed = time.time() - start\n\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n\n        print(f\"Epoch {epoch}/{epochs} - time: {elapsed:.1f}s - train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f} - val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}\")\n\n        # Save best\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_state = model.state_dict()\n            torch.save(best_state, os.path.join('/mnt/data/pytorch_day2', model_name))\n            print('Saved best model with val_acc =', best_val_acc)\n\n    # At the end, return history and last evaluation\n    return history, (val_loss, val_acc, val_preds, val_labels)\n\n# Run a short experiment: 5 epochs with BATCH_SIZE already set to 64\nmodel = SimpleCNN().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\nhistory, eval_res = run_training(model, train_loader, test_loader, optimizer, criterion, device, epochs=5, scheduler=scheduler, model_name='mnist_cnn_bs64.pth')\nplot_history(history, title_prefix='MNIST_CNN_bs64')\n\n# Confusion matrix and classification report\nval_loss, val_acc, val_preds, val_labels = eval_res\ncm = confusion_matrix(val_labels, val_preds)\nprint('Confusion matrix (counts):')\nplot_confusion_matrix(cm, classes=[str(i) for i in range(10)], normalize=False)\nprint('Classification report:')\nprint(classification_report(val_labels, val_preds))\n",
      "outputs": []
    },
    {
      "id": "7d0e5f4e",
      "cell_type": "markdown",
      "source": "\n## 6) So s√°nh Batch Size (64 vs 128)\n- D·ª±ng h√†m `experiment_batch_size` ƒë·ªÉ train ng·∫Øn (v√≠ d·ª• 5 epoch) v·ªõi batch size kh√°c nhau v√† so s√°nh loss/acc.\n- L∆∞u √Ω: khi tƒÉng batch size, learning rate c≈©ng c√≥ th·ªÉ c·∫ßn tƒÉng (rule-of-thumb: LR ‚àù batch_size), nh∆∞ng ·ªü ƒë√¢y ta gi·ªØ LR c·ªë ƒë·ªãnh ƒë·ªÉ quan s√°t kh√°c bi·ªát.\n",
      "metadata": {}
    },
    {
      "id": "20e193fd",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def experiment_batch_size(batch_size, epochs=5):\n    print('Running experiment with batch_size =', batch_size)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    model = SimpleCNN().to(device)\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    history, eval_res = run_training(model, train_loader, test_loader, optimizer, criterion, device, epochs=epochs,\n                                     scheduler=optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1),\n                                     model_name=f'mnist_cnn_bs{batch_size}.pth')\n    return history, eval_res\n\n# Run experiments\nhist64, res64 = experiment_batch_size(64, epochs=5)\nhist128, res128 = experiment_batch_size(128, epochs=5)\n\nprint('\\n--- Summary ---')\nprint('BS=64 val_acc:', res64[1])\nprint('BS=128 val_acc:', res128[1])\n\n# Plot comparison (accuracy)\nplt.figure(figsize=(6,4))\nplt.plot(hist64['val_acc'], label='val_acc_bs64')\nplt.plot(hist128['val_acc'], label='val_acc_bs128')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Accuracy')\nplt.legend()\nplt.title('Compare validation accuracy')\nplt.show()\n",
      "outputs": []
    },
    {
      "id": "70da686b",
      "cell_type": "markdown",
      "source": "\n## 7) L∆∞u & T·∫£i model\nV√≠ d·ª• l∆∞u `state_dict` v√† c√°ch load ƒë·ªÉ inference.\n",
      "metadata": {}
    },
    {
      "id": "5dc9db95",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Load best model example\nmodel_path = '/mnt/data/pytorch_day2/mnist_cnn_bs64.pth'\nif os.path.exists(model_path):\n    model = SimpleCNN().to(device)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n    print('Loaded model from', model_path)\nelse:\n    print('Model file not found:', model_path)\n\n# Inference on few test images\nmodel.eval()\nimgs, labels = next(iter(test_loader))\nimgs = imgs.to(device)\nlabels = labels.to(device)\nwith torch.no_grad():\n    logits = model(imgs[:16])\n    preds = torch.argmax(logits, dim=1)\n\n# show first 8 predictions\nplt.figure(figsize=(12,3))\nfor i in range(8):\n    plt.subplot(1,8,i+1)\n    img = imgs[i].cpu().squeeze().numpy()\n    plt.imshow(img, cmap='gray')\n    plt.title(f'p={preds[i].item()}, t={labels[i].item()}')\n    plt.axis('off')\nplt.show()\n",
      "outputs": []
    },
    {
      "id": "8256dd3a",
      "cell_type": "markdown",
      "source": "\n## 8) G·ª£i √Ω tr·∫£ l·ªùi ph·ªèng v·∫•n ‚Äî C√°c c√¢u h·ªèi ph·ªï bi·∫øn & c√°ch tr·∫£ l·ªùi ng·∫Øn\n- **Q:** T·∫°i sao d√πng `CrossEntropyLoss` cho classification?\n  - **A:** V√¨ `CrossEntropyLoss` k·∫øt h·ª£p softmax + NLL, ph√π h·ª£p cho multi-class logits ƒë·∫ßu ra.\n\n- **Q:** Hi·ªÉu `requires_grad` l√† g√¨?\n  - **A:** N·∫øu tensor `requires_grad=True`, PyTorch s·∫Ω theo d√µi c√°c thao t√°c ƒë·ªÉ t√≠nh gradient trong backprop.\n\n- **Q:** Khi n√†o d√πng `model.train()` vs `model.eval()`?\n  - **A:** `model.train()` b·∫≠t dropout/batchnorm ·ªü ch·∫ø ƒë·ªô train; `model.eval()` t·∫Øt dropout v√† d√πng running stats c·ªßa batchnorm.\n\n- **Q:** L√†m sao tr√°nh overfitting?\n  - **A:** Data augmentation, dropout, weight decay (L2), early stopping, tƒÉng d·ªØ li·ªáu, reducing model capacity.\n\n- **Q:** N√™n tƒÉng LR hay batch size ƒë·ªÉ train nhanh?\n  - **A:** C√¢n nh·∫Øc; th∆∞·ªùng LR ‚àù batch_size nh∆∞ng ph·∫£i ƒëi·ªÅu ch·ªânh. C√≥ k·ªπ thu·∫≠t LR warmup, cyclical LR.\n\n- **Q:** M√¥ t·∫£ nhanh training loop?\n  - **A:** forward -> compute loss -> backward (loss.backward()) -> optimizer.step() -> zero_grad().\n\n- **Q:** Kh√°c bi·ªát `state_dict` v√† l∆∞u c·∫£ model?\n  - **A:** `state_dict` ch·ª©a weights; l∆∞u c·∫£ model (pickle) c√≥ th·ªÉ d·ªÖ load nh∆∞ng √≠t linh ho·∫°t + c√≥ v·∫•n ƒë·ªÅ t∆∞∆°ng th√≠ch.\n",
      "metadata": {}
    },
    {
      "id": "eb6d136e",
      "cell_type": "markdown",
      "source": "\n## 9) B√†i t·∫≠p (1h) ‚Äî Em l√†m code trong notebook\n1. Train CNN tr√™n MNIST 5‚Äì10 epoch (n·∫øu th·ªùi gian), in loss/accuracy m·ªói epoch (ƒë√£ c√≥ trong notebook).\n2. Th·ª≠ tƒÉng batch size l√™n 128, so s√°nh loss/accuracy (ƒë√£ c√≥ experiment function).\n3. (Bonus) Thay optimizer sang `Adam(lr=1e-3)` v√† xem kh√°c bi·ªát.\n4. (CV task) Th·ª≠ chuy·ªÉn dataset sang **CIFAR10**: thay transform (normalize 3 channels) v√† s·ª≠a m·∫°ng (input channels=3, c·∫ßn small changes).\n\nKhi xong, g·ª≠i cho th·∫ßy file logs ho·∫∑c screenshot training logs ƒë·ªÉ th·∫ßy review.\n",
      "metadata": {}
    }
  ]
}